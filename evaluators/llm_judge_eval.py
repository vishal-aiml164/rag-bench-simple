# Placeholder for LLM-as-a-judge. Wire your provider of choice (Azure OpenAI, OpenAI, etc.).
def llm_judge(question: str, answer: str, context: str) -> dict:
    # Return a dict with scores and justifications.
    return {"score": None, "notes": "Not implemented: connect your LLM provider."}
